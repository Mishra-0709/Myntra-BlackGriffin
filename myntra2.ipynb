{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOemb1FgkXXb4GlFxezVhE5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mishra-0709/Myntra-BlackGriffin/blob/main/myntra2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import random\n",
        "from sklearn.cluster import KMeans\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import os\n",
        "\n",
        "# Load YOLO model\n",
        "model = YOLO('yolov8n.pt')  # or use a more specific model trained for clothing detection\n",
        "\n",
        "def get_dominant_colors(image, n_colors=3):\n",
        "    # Reshape the image to be a list of pixels\n",
        "    pixels = image.reshape(-1, 3)\n",
        "\n",
        "    # Perform K-means clustering\n",
        "    kmeans = KMeans(n_clusters=n_colors)\n",
        "    kmeans.fit(pixels)\n",
        "\n",
        "    # Get the colors\n",
        "    colors = kmeans.cluster_centers_\n",
        "\n",
        "    # Convert to hex\n",
        "    hex_colors = ['#%02x%02x%02x' % tuple(map(int, color)) for color in colors]\n",
        "\n",
        "    return hex_colors\n",
        "\n",
        "def detect_clothing_and_colors(image_path):\n",
        "    # Read the image\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Perform YOLO detection\n",
        "    results = model(image)\n",
        "\n",
        "    # Extract clothing items\n",
        "    clothing_items = []\n",
        "    for result in results:\n",
        "        boxes = result.boxes\n",
        "        for box in boxes:\n",
        "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
        "            class_id = int(box.cls[0])\n",
        "            if model.names[class_id] in ['person', 'shirt', 'dress', 'pants']:  # Add more clothing classes as needed\n",
        "                clothing_items.append(image[y1:y2, x1:x2])\n",
        "\n",
        "    # Extract dominant colors\n",
        "    dominant_colors = []\n",
        "    for item in clothing_items:\n",
        "        colors = get_dominant_colors(item)\n",
        "        dominant_colors.extend(colors)\n",
        "\n",
        "    return list(set(dominant_colors))[:10]  # Return up to 10 unique colors\n",
        "\n",
        "def detect_skin_tone(image_path):\n",
        "    # For simplicity, we'll use a basic approach to detect skin tone\n",
        "    # In a real-world scenario, you'd want a more sophisticated method\n",
        "    image = cv2.imread(image_path)\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "    if len(faces) == 0:\n",
        "        return \"medium\"  # Default if no face detected\n",
        "\n",
        "    (x, y, w, h) = faces[0]\n",
        "    face_roi = image[y:y+h, x:x+w]\n",
        "    average_color = np.mean(face_roi, axis=(0, 1))\n",
        "\n",
        "    # Simplified skin tone classification\n",
        "    b, g, r = average_color\n",
        "    if r > 200 and g > 200 and b > 200:\n",
        "        return \"very_fair\"\n",
        "    elif r > 180 and g > 180 and b > 180:\n",
        "        return \"fair\"\n",
        "    elif r > 160 and g > 160 and b > 160:\n",
        "        return \"light\"\n",
        "    elif r > 140 and g > 140 and b > 140:\n",
        "        return \"medium_light\"\n",
        "    elif r > 120 and g > 120 and b > 120:\n",
        "        return \"medium\"\n",
        "    elif r > 100 and g > 100 and b > 100:\n",
        "        return \"medium_tan\"\n",
        "    elif r > 80 and g > 80 and b > 80:\n",
        "        return \"tan\"\n",
        "    else:\n",
        "        return \"dark\"\n",
        "\n",
        "# Define skin tone to color recommendations (simplified version)\n",
        "skin_tone_colors = {\n",
        "    \"very_fair\": [\"#FFD700\", \"#008080\", \"#800080\", \"#FF69B4\", \"#4B0082\", \"#00CED1\", \"#FF4500\", \"#1E90FF\", \"#32CD32\", \"#FF1493\"],\n",
        "    \"fair\": [\"#FF6347\", \"#4682B4\", \"#9ACD32\", \"#FF69B4\", \"#8A2BE2\", \"#20B2AA\", \"#FF4500\", \"#4169E1\", \"#32CD32\", \"#FF1493\"],\n",
        "    \"light\": [\"#FFA07A\", \"#6495ED\", \"#7FFF00\", \"#DDA0DD\", \"#9932CC\", \"#48D1CC\", \"#FF6347\", \"#1E90FF\", \"#3CB371\", \"#FF69B4\"],\n",
        "    \"medium_light\": [\"#F4A460\", \"#4169E1\", \"#32CD32\", \"#DA70D6\", \"#8B008B\", \"#40E0D0\", \"#FF4500\", \"#1E90FF\", \"#228B22\", \"#FF1493\"],\n",
        "    \"medium\": [\"#CD853F\", \"#0000FF\", \"#228B22\", \"#BA55D3\", \"#9400D3\", \"#00CED1\", \"#FF6347\", \"#4682B4\", \"#2E8B57\", \"#FF69B4\"],\n",
        "    \"medium_tan\": [\"#D2691E\", \"#0000CD\", \"#006400\", \"#9370DB\", \"#8B008B\", \"#20B2AA\", \"#FF4500\", \"#4169E1\", \"#2E8B57\", \"#FF1493\"],\n",
        "    \"tan\": [\"#8B4513\", \"#000080\", \"#006400\", \"#8A2BE2\", \"#4B0082\", \"#008B8B\", \"#B22222\", \"#4682B4\", \"#228B22\", \"#C71585\"],\n",
        "    \"dark\": [\"#A0522D\", \"#191970\", \"#006400\", \"#9932CC\", \"#4B0082\", \"#008080\", \"#8B0000\", \"#4169E1\", \"#2E8B57\", \"#C71585\"],\n",
        "}\n",
        "\n",
        "def recommend_colors(image_path):\n",
        "    # Detect skin tone\n",
        "    skin_tone = detect_skin_tone(image_path)\n",
        "\n",
        "    # Get dominant colors from clothing\n",
        "    dominant_colors = detect_clothing_and_colors(image_path)\n",
        "\n",
        "    # Update skin tone color recommendations with dominant colors\n",
        "    if skin_tone in skin_tone_colors:\n",
        "        skin_tone_colors[skin_tone] = list(set(skin_tone_colors[skin_tone] + dominant_colors))\n",
        "\n",
        "    # Recommend colors\n",
        "    recommended_colors = random.sample(skin_tone_colors[skin_tone], min(3, len(skin_tone_colors[skin_tone])))\n",
        "\n",
        "    return skin_tone, recommended_colors\n",
        "\n",
        "def within_threshold(check, threshold):\n",
        "    avg = sum(check) / 3\n",
        "    if avg > 230:\n",
        "        return True\n",
        "    return all(avg - threshold <= value <= avg + threshold for value in check)\n",
        "\n",
        "def euclidean_sim(arr, check):\n",
        "    for ele in arr:\n",
        "        ele = [e-a for e,a in zip(ele,check)]\n",
        "        res = np.linalg.norm(ele)/442.4\n",
        "        if res <= 0.2:\n",
        "            return False\n",
        "        if within_threshold(check, 5):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def getSkinToneClothColor(image_path):\n",
        "    # Detect skin tone\n",
        "    skin_tone = detect_skin_tone(image_path)\n",
        "\n",
        "    image = cv2.imread(image_path)\n",
        "    results = model(image)\n",
        "\n",
        "    cropped_image = cv2.imread(image_path)\n",
        "    labels = results.xyxyn[0][:, -1].numpy()\n",
        "    coords = results.xyxyn[0][:, :-1].numpy()\n",
        "\n",
        "    for i in range(0, len(labels)):\n",
        "        # as 0 represents person in coco dataset\n",
        "        if labels[i] == 0:\n",
        "            x1, y1, x2, y2, pred = coords[i]\n",
        "            height, width, _ = image.shape\n",
        "            x1, y1, x2, y2 = int(x1 * width), int(y1 * height), int(x2 * width), int(y2 * height)\n",
        "            cropped_image = cropped_image[y1:y2, x1:x2]\n",
        "            break\n",
        "\n",
        "    height, width, _ = np.shape(cropped_image)\n",
        "    data = np.reshape(cropped_image, (height * width, 3))\n",
        "    data = np.float32(data)\n",
        "\n",
        "    number_clusters = 7\n",
        "    kmeans = KMeans(n_clusters=number_clusters)\n",
        "    kmeans.fit(data)\n",
        "\n",
        "    centers = kmeans.cluster_centers_\n",
        "    labels = kmeans.labels_\n",
        "    rgb_values = []\n",
        "\n",
        "    for index, row in enumerate(centers):\n",
        "        # Extract RGB values from the row\n",
        "        b, g, r = int(row[0]), int(row[1]), int(row[2])\n",
        "        # put a check of cosine similarity\n",
        "        if euclidean_sim(rgb_values, [r, g, b]):\n",
        "            rgb_values.append([r, g, b])\n",
        "\n",
        "    return skin_tone, rgb_values\n",
        "\n",
        "def main():\n",
        "    # Example usage\n",
        "    image_path = \"/content/1.jpg\"  # Replace with your image path\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"Error: Image file '{image_path}' not found.\")\n",
        "        return\n",
        "\n",
        "    skin_tone, recommended_colors = recommend_colors(image_path)\n",
        "    print(f\"Detected skin tone: {skin_tone}\")\n",
        "    print(f\"Recommended colors: {recommended_colors}\")\n",
        "\n",
        "    # Prepare a single color dictionary entry for demonstration\n",
        "    color_dict = {\n",
        "        \"#373028\": [[255, 0, 0], [0, 255, 0], [0, 0, 255]]  # Example colors\n",
        "    }\n",
        "\n",
        "    # Save JSON data\n",
        "    json_data = json.dumps(color_dict)\n",
        "    with open('data.json', 'w') as f:\n",
        "        f.write(json_data)\n",
        "\n",
        "def display_color_recommendations():\n",
        "    if not os.path.exists('data.json'):\n",
        "        print(\"Error: 'data.json' file not found.\")\n",
        "        return\n",
        "\n",
        "    with open('data.json', 'r') as f:\n",
        "        json_data = json.load(f)\n",
        "\n",
        "    image_path = '/content/1.jpg'  # Replace with your image path\n",
        "    if not os.path.exists(image_path):\n",
        "        print(f\"Error: Image file '{image_path}' not found.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Try to open the image with OpenCV first\n",
        "        cv_image = cv2.imread(image_path)\n",
        "        if cv_image is None:\n",
        "            raise UnidentifiedImageError(f\"Error: Unable to read the image file '{image_path}' with OpenCV.\")\n",
        "\n",
        "        # Convert the image to a format PIL can use\n",
        "        cv_image_rgb = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)\n",
        "        pil_image = Image.fromarray(cv_image_rgb)\n",
        "    except UnidentifiedImageError:\n",
        "        print(f\"Error: Unable to identify the image file '{image_path}'.\")\n",
        "        return\n",
        "\n",
        "    # Display the image and recommended colors\n",
        "    plt.imshow(pil_image)\n",
        "    suggestions = random.sample(json_data[list(json_data.keys())[0]], 3)\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(5, 3))\n",
        "\n",
        "    for i, color in enumerate(suggestions):\n",
        "        r, g, b = color\n",
        "        axs[i].imshow([[[r/255, g/255, b/255]]])\n",
        "        axs[i].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    display_color_recommendations()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSfvf5zbrfB3",
        "outputId": "8e26c067-3a4c-4334-e6d4-c9bf4da094ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x448 2 persons, 1 handbag, 996.0ms\n",
            "Speed: 3.7ms preprocess, 996.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 448)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected skin tone: medium\n",
            "Recommended colors: ['#4682B4', '#888c8a', '#0000FF']\n"
          ]
        }
      ]
    }
  ]
}